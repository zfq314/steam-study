

###### 1、flume taildirsourse文件重复

配置文件

flume的组件

source-channel-sink

flume的启动命令

/data/program/flume/bin/flume-ng agent --conf-file /data/program/flume/conf/test.conf --name a1  -Dflume.root.logger=INFO,console

taildirsource

​	优点：支持监控多目录，断点续传

​	缺点：如果监控的文件修改名字，就会重复消费，查看 taidir_position 的内容，inode+filename来做监控文件的判断

​				解决方案：

​				使用不改名字的日志框架 logback等

​				或者修改源码解决

如果把监控的的文件名字写死，会出现零点漂移，数据丢失的情况，接近零点的时候，任务失败，然后恢复。会造成数据丢失的情况。

test.conf，修改源码，监控文件如果重命名，数据不重复读

```
##组件
a1.sources = r1
a1.channels = c1
a1.sinks = k1

##source
a1.sources.r1.type = TAILDIR
a1.sources.r1.positionFile = /data/program/flume/taildir_position.json
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /data/program/flume/files/file.*

##sink
a1.sinks.k1.type = logger
##channel
a1.channels.c1.type = memory

##拼装
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1


```

###### 2、修改源码的步骤：

1. ​	将原来的项目拷贝过来，远程拉取下来，

2. ​	然后将某个module放入到自己的项目中，修改pom文件

3. ​	修改代码，然后打包，修改源码的过程中，尽量不要修改包名和类名

4. ​	打包之后，然后上传到相应的服务器上面。然后到相应的lib上面，

5. ​	上传之后，先验证jar的功能是否使用，如果基本功能无异常，然后，测试自己的修改的模块，看是否能够完成自己的需求。


###### 3、提高代码质量

- 整理思路-看着敲--根据注释敲--自己敲

- 根据注释，自己敲

- 自己敲


###### 4、在数据采集的阶段 kafka 充当的角色，生产者和消费者

kafkachannel的好好处，省略了sink阶段

```
采集工程中的三种用法，也可做生产者也可以消费者，具体的实现
source-kafkanchannel-sink

source-kafkachannel

kafkachannel-sink
```

###### 5、sqoop导出数据

```
全量数据 ：where 1=1

增量数据：where create_time=当天

变化和新增： where create_time=当天 or operate_time=当天

特殊表：全量导出 
```



###### 6、面试过程的框架梳理

```
逻辑线：数据流-(某个框架)监控-优化-配置
大数据组件的复习方式，先学习用，在研究源码级别
```

###### 7、批量替换一个目录下所有文件的某个字符传

```
sed -i 's/hadoop31/hadoop33/g' ./*.json
```

###### 8、某个目录下文件的个数

```
ls -l | grep "^-" | wc -l
```

###### 9、kafka

​	producer 

​			ack 0 1 -1 

​      保证生产者丢失数据，设置ack -1 

​	 拦截器 序列化器 分区器 发送流程 sender main 幂等性，事务 

​	分区规则

​	有指定分区，则发指定分区

​	没有指定分区 ，则根据key值hash 

​	没有指定分区也没有key,轮询 

broker

​	topic

​		副本： 高可靠 isr leo hw

​		分区： 高并发，负载均衡，防止热点

consumer:

​	分区分配规则

​	offset保存

​	默认 _ _consumer_offsets 主题

​	其他 手动维护 offset （mysql）

```
保存数据&保存offset写到一个事务

精准一次消费
```

先保存数据后保存offset 重复数据+幂等性（精准一次消费）：（如果不能做到精准消费）

先保存offset后保存数据 丢失数据

